Right now I've implemented :
.)Text Processing: Utilizes NLTK for tokenization, lemmatization, and removal of punctuation to process and understand user input.
.)TF-IDF Vectorization: Employs the TF-IDF Vectorizer to transform text data into meaningful vectors for similarity comparisons.
.)Cosine Similarity: Implements cosine similarity to match user queries with the most relevant information extracted from Wikipedia articles.
Yet the output isn't as refined as I would like, but then again this is no chatgpt. 
The next attempt would be to implement entity recognition with Spacy to get a better response.
